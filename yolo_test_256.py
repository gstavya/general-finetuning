import os

import io

import yaml

import torch

from pathlib import Path

from azure.storage.blob import BlobServiceClient

from ultralytics import YOLO

import multiprocessing

from tqdm import tqdm

import tempfile

import warnings

import shutil

import json

import time # Import time for potential sleep



# Set YOLO config directory to avoid permission warnings

os.environ['YOLO_CONFIG_DIR'] = '/tmp/yolo_config'



# Suppress Ultralytics warnings during multiprocessing

warnings.filterwarnings('ignore', message='user config directory')

warnings.filterwarnings('ignore', message='Error decoding JSON')



# --- (Your download_blob, download_from_azure, download_and_extract_checkpoint, create_data_yaml functions remain unchanged) ---

# Paste them here if you want a single runnable block for testing, otherwise assume they are defined above.



def save_full_checkpoint_to_azure(trainer, connection_string, container_name, epoch):

Â  Â  """Save complete checkpoint with all training state to Azure."""

Â  Â  try:

Â  Â  Â  Â  print(f"\nğŸ”„ Starting checkpoint save for epoch {epoch}...")



Â  Â  Â  Â  blob_service_client = BlobServiceClient.from_connection_string(connection_string)



Â  Â  Â  Â  # Ensure container exists

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  container_client = blob_service_client.create_container(container_name)

Â  Â  Â  Â  Â  Â  print(f"Container '{container_name}' created.")

Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  if "ContainerAlreadyExists" in str(e):

Â  Â  Â  Â  Â  Â  Â  Â  container_client = blob_service_client.get_container_client(container_name)

Â  Â  Â  Â  Â  Â  Â  Â  print(f"Container '{container_name}' already exists.")

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  raise # Re-raise other exceptions



Â  Â  Â  Â  # Create temporary directory for checkpoint files

Â  Â  Â  Â  with tempfile.TemporaryDirectory() as temp_dir:

Â  Â  Â  Â  Â  Â  checkpoint_dir = os.path.join(temp_dir, f'checkpoint_epoch_{epoch}')

Â  Â  Â  Â  Â  Â  os.makedirs(checkpoint_dir, exist_ok=True)

Â  Â  Â  Â  Â  Â  print(f"Â  DEBUG: Checkpoint temporary directory created at: {checkpoint_dir}")



Â  Â  Â  Â  Â  Â  # --- Save the model weights ---

Â  Â  Â  Â  Â  Â  weights_path = os.path.join(checkpoint_dir, 'weights.pt')

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  # CRITICAL CHECK: Verify trainer.last and wait if necessary

Â  Â  Â  Â  Â  Â  if trainer.last and os.path.exists(trainer.last):

Â  Â  Â  Â  Â  Â  Â  Â  # Add a small delay to ensure file is fully written by Ultralytics

Â  Â  Â  Â  Â  Â  Â  Â  # This is a common workaround for callback timing issues

Â  Â  Â  Â  Â  Â  Â  Â  time.sleep(0.5)Â 

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  shutil.copy(trainer.last, weights_path)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  âœ“ Model weights copied from {trainer.last}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  DEBUG: Copied weights file size: {os.path.getsize(weights_path)} bytes")

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as copy_e:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  âŒ ERROR: Failed to copy model weights from {trainer.last}. Error: {copy_e}")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Fallback to direct save if copy fails

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print("Â  Attempting direct model save as fallback...")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  trainer.model.save(weights_path)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  âœ“ Model weights (fallback direct save) saved")

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  DEBUG: trainer.last is not available or path does not exist: {trainer.last}")

Â  Â  Â  Â  Â  Â  Â  Â  print("Â  Attempting direct model save as fallback...")

Â  Â  Â  Â  Â  Â  Â  Â  trainer.model.save(weights_path)

Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  âœ“ Model weights (fallback direct save) saved")

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  # Save optimizer state

Â  Â  Â  Â  Â  Â  optimizer_path = os.path.join(checkpoint_dir, 'optimizer.pt')

Â  Â  Â  Â  Â  Â  if hasattr(trainer, 'optimizer') and trainer.optimizer: # More robust check

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  torch.save(trainer.optimizer.state_dict(), optimizer_path)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  âœ“ Optimizer state saved")

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as opt_e:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  âŒ ERROR: Failed to save optimizer state. Error: {opt_e}")

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  â„¹ï¸Â  Optimizer object not found on trainer or is None.")



Â  Â  Â  Â  Â  Â  # Save training args and state

Â  Â  Â  Â  Â  Â  training_state = {

Â  Â  Â  Â  Â  Â  Â  Â  'epoch': epoch,

Â  Â  Â  Â  Â  Â  Â  Â  'best_fitness': trainer.best_fitness if hasattr(trainer, 'best_fitness') else None,

Â  Â  Â  Â  Â  Â  Â  Â  'fitness': trainer.fitness if hasattr(trainer, 'fitness') else None,

Â  Â  Â  Â  Â  Â  Â  Â  'ema': trainer.ema.state_dict() if hasattr(trainer, 'ema') and trainer.ema else None,

Â  Â  Â  Â  Â  Â  Â  Â  'updates': trainer.optimizer.state_dict()['state'].get(0, {})['step'] if hasattr(trainer, 'optimizer') and trainer.optimizer and trainer.optimizer.state_dict()['state'] else 0,

Â  Â  Â  Â  Â  Â  Â  Â  'train_args': vars(trainer.args) if hasattr(trainer, 'args') and trainer.args else {},

Â  Â  Â  Â  Â  Â  }



Â  Â  Â  Â  Â  Â  state_path = os.path.join(checkpoint_dir, 'training_state.pt')

Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  torch.save(training_state, state_path)

Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  âœ“ Training state saved")

Â  Â  Â  Â  Â  Â  except Exception as state_e:

Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  âŒ ERROR: Failed to save training state. Error: {state_e}")



Â  Â  Â  Â  Â  Â  # Save results CSV if exists

Â  Â  Â  Â  Â  Â  if hasattr(trainer, 'csv') and trainer.csv and os.path.exists(trainer.csv):

Â  Â  Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  shutil.copy(trainer.csv, os.path.join(checkpoint_dir, 'results.csv'))

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  âœ“ Results CSV saved from {trainer.csv}")

Â  Â  Â  Â  Â  Â  Â  Â  except Exception as csv_e:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  âŒ ERROR: Failed to copy results CSV from {trainer.csv}. Error: {csv_e}")

Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  â„¹ï¸Â  No results CSV to save or path invalid: {getattr(trainer, 'csv', 'N/A')}")



Â  Â  Â  Â  Â  Â  # Create a tar archive of the checkpoint directory

Â  Â  Â  Â  Â  Â  tar_path_base = os.path.join(temp_dir, f'checkpoint_epoch_{epoch}')

Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  shutil.make_archive(tar_path_base, 'tar', checkpoint_dir)

Â  Â  Â  Â  Â  Â  Â  Â  tar_path = tar_path_base + '.tar' # make_archive adds the extension

Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  âœ“ Archive created at {tar_path}")

Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  DEBUG: Archive file size: {os.path.getsize(tar_path)} bytes")

Â  Â  Â  Â  Â  Â  except Exception as archive_e:

Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  âŒ ERROR: Failed to create archive. Error: {archive_e}")

Â  Â  Â  Â  Â  Â  Â  Â  raise # Re-raise to stop if archive creation fails



Â  Â  Â  Â  Â  Â  # Upload the tar file to Azure

Â  Â  Â  Â  Â  Â  blob_name = f'checkpoint_epoch_{epoch}.tar'

Â  Â  Â  Â  Â  Â  blob_client = container_client.get_blob_client(blob_name)



Â  Â  Â  Â  Â  Â  print(f"Â  ğŸ“¤ Uploading to Azure as: {blob_name}...")

Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  with open(tar_path, "rb") as data:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  blob_client.upload_blob(data, overwrite=True)

Â  Â  Â  Â  Â  Â  Â  Â  print(f"âœ… Checkpoint for epoch {epoch} successfully uploaded to Azure!\n")

Â  Â  Â  Â  Â  Â  except Exception as upload_e:

Â  Â  Â  Â  Â  Â  Â  Â  print(f"Â  âŒ ERROR: Failed to upload checkpoint to Azure Blob Storage. Error: {upload_e}")

Â  Â  Â  Â  Â  Â  Â  Â  raise # Re-raise to show the full Azure error



Â  Â  except Exception as e:

Â  Â  Â  Â  print(f"âŒ WARNING: An unexpected error occurred during checkpoint saving. Error: {e}\n")

Â  Â  Â  Â  import traceback

Â  Â  Â  Â  traceback.print_exc()



# --- (Your main function and __name__ == '__main__' block remain unchanged) ---

# You'll need to paste the rest of your original script here to make it runnable.

# Ensure the main() function calls the save_full_checkpoint_to_azure with the actual trainer object.

# The `on_train_epoch_end` and `on_epoch_end_alt` callbacks should use this modified function.



def download_blob(args):

Â  Â  """Worker function to download a single blob."""

Â  Â  blob_name, connection_string, container_name, local_dir = args



Â  Â  # Suppress warnings in worker processes

Â  Â  import warnings

Â  Â  warnings.filterwarnings('ignore')

Â  Â  os.environ['YOLO_CONFIG_DIR'] = '/tmp/yolo_config'



Â  Â  try:

Â  Â  Â  Â  blob_service_client = BlobServiceClient.from_connection_string(connection_string)

Â  Â  Â  Â  blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)



Â  Â  Â  Â  # Create local path maintaining directory structure

Â  Â  Â  Â  local_path = os.path.join(local_dir, blob_name)

Â  Â  Â  Â  os.makedirs(os.path.dirname(local_path), exist_ok=True)



Â  Â  Â  Â  # Download blob

Â  Â  Â  Â  with open(local_path, "wb") as file:

Â  Â  Â  Â  Â  Â  download_stream = blob_client.download_blob()

Â  Â  Â  Â  Â  Â  file.write(download_stream.readall())



Â  Â  Â  Â  return f"Downloaded {blob_name}"

Â  Â  except Exception as e:

Â  Â  Â  Â  return f"Failed to download {blob_name}: {e}"



def download_from_azure(connection_string, container_name, local_dir):

Â  Â  """Download all files from Azure container to local directory."""

Â  Â  if os.path.exists(local_dir) and len(list(Path(local_dir).rglob('*'))) > 100:

Â  Â  Â  Â  print(f"Data already exists in '{local_dir}'. Skipping download.")

Â  Â  Â  Â  return



Â  Â  print(f"Downloading data from Azure container '{container_name}' to '{local_dir}'...")

Â  Â  os.makedirs(local_dir, exist_ok=True)



Â  Â  try:

Â  Â  Â  Â  blob_service_client = BlobServiceClient.from_connection_string(connection_string)

Â  Â  Â  Â  container_client = blob_service_client.get_container_client(container_name)



Â  Â  Â  Â  # List all blobs

Â  Â  Â  Â  blobs = list(container_client.list_blobs())

Â  Â  Â  Â  if not blobs:

Â  Â  Â  Â  Â  Â  print(f"Warning: No files found in container '{container_name}'.")

Â  Â  Â  Â  Â  Â  return



Â  Â  Â  Â  # Prepare download tasks

Â  Â  Â  Â  tasks = [(blob.name, connection_string, container_name, local_dir) for blob in blobs]



Â  Â  Â  Â  # Download in parallel

Â  Â  Â  Â  with multiprocessing.Pool(processes=os.cpu_count()) as pool:

Â  Â  Â  Â  Â  Â  for _ in tqdm(pool.imap_unordered(download_blob, tasks), total=len(tasks), desc="Downloading files"):

Â  Â  Â  Â  Â  Â  Â  Â  pass



Â  Â  Â  Â  print(f"âœ… Download complete. All files saved to '{local_dir}'.")



Â  Â  except Exception as e:

Â  Â  Â  Â  print(f"FATAL: Error downloading from Azure: {e}")

Â  Â  Â  Â  raise



def download_and_extract_checkpoint(connection_string, container_name, blob_name, extract_dir):

Â  Â  """Download and extract checkpoint from Azure."""

Â  Â  try:

Â  Â  Â  Â  blob_service_client = BlobServiceClient.from_connection_string(connection_string)

Â  Â  Â  Â  blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)



Â  Â  Â  Â  # Download tar file

Â  Â  Â  Â  tar_path = os.path.join(extract_dir, blob_name)

Â  Â  Â  Â  with open(tar_path, "wb") as f:

Â  Â  Â  Â  Â  Â  f.write(blob_client.download_blob().readall())



Â  Â  Â  Â  # Extract tar file

Â  Â  Â  Â  import tarfile

Â  Â  Â  Â  with tarfile.open(tar_path, 'r') as tar:

Â  Â  Â  Â  Â  Â  tar.extractall(extract_dir)



Â  Â  Â  Â  # Remove tar file

Â  Â  Â  Â  os.remove(tar_path)



Â  Â  Â  Â  # Return path to extracted checkpoint directory

Â  Â  Â  Â  checkpoint_name = blob_name.replace('.tar', '')

Â  Â  Â  Â  return os.path.join(extract_dir, checkpoint_name)



Â  Â  except Exception as e:

Â  Â  Â  Â  print(f"Failed to download/extract checkpoint: {e}")

Â  Â  Â  Â  return None



def create_data_yaml(local_data_dir):

Â  Â  """Create data.yaml file for YOLO training."""

Â  Â  data_yaml_path = os.path.join(local_data_dir, 'data.yaml')



Â  Â  # Check if data.yaml already exists in the downloaded data

Â  Â  if os.path.exists(data_yaml_path):

Â  Â  Â  Â  print(f"Using existing data.yaml from {data_yaml_path}")

Â  Â  Â  Â  # Update paths to be absolute

Â  Â  Â  Â  with open(data_yaml_path, 'r') as f:

Â  Â  Â  Â  Â  Â  data_config = yaml.safe_load(f)



Â  Â  Â  Â  # Update paths to absolute paths

Â  Â  Â  Â  data_config['path'] = os.path.abspath(local_data_dir)

Â  Â  Â  Â  if 'train' in data_config:

Â  Â  Â  Â  Â  Â  data_config['train'] = os.path.join(os.path.abspath(local_data_dir), 'train/images')

Â  Â  Â  Â  if 'val' in data_config:

Â  Â  Â  Â  Â  Â  data_config['val'] = os.path.join(os.path.abspath(local_data_dir), 'val/images')

Â  Â  Â  Â  if 'test' in data_config:

Â  Â  Â  Â  Â  Â  data_config['test'] = os.path.join(os.path.abspath(local_data_dir), 'test/images')



Â  Â  Â  Â  # Save updated config

Â  Â  Â  Â  updated_yaml_path = os.path.join(local_data_dir, 'data_updated.yaml')

Â  Â  Â  Â  with open(updated_yaml_path, 'w') as f:

Â  Â  Â  Â  Â  Â  yaml.dump(data_config, f, default_flow_style=False)



Â  Â  Â  Â  return updated_yaml_path



Â  Â  else:

Â  Â  Â  Â  # Create new data.yaml if it doesn't exist

Â  Â  Â  Â  print("Creating new data.yaml file...")

Â  Â  Â  Â  data_config = {

Â  Â  Â  Â  Â  Â  'path': os.path.abspath(local_data_dir),

Â  Â  Â  Â  Â  Â  'train': os.path.join(os.path.abspath(local_data_dir), 'train/images'),

Â  Â  Â  Â  Â  Â  'val': os.path.join(os.path.abspath(local_data_dir), 'val/images'),

Â  Â  Â  Â  Â  Â  'test': os.path.join(os.path.abspath(local_data_dir), 'test/images'),

Â  Â  Â  Â  Â  Â  'nc': 1,Â  # Number of classes

Â  Â  Â  Â  Â  Â  'names': ['sidewalk']Â  # Class names

Â  Â  Â  Â  }



Â  Â  Â  Â  with open(data_yaml_path, 'w') as f:

Â  Â  Â  Â  Â  Â  yaml.dump(data_config, f, default_flow_style=False)



Â  Â  Â  Â  return data_yaml_path



def main():

Â  Â  # --- Configuration ---

Â  Â  SOURCE_DATA_CONTAINER = "13ksidewalk60"

Â  Â  CHECKPOINT_CONTAINER = "13ksidewalk60yolotest"

Â  Â  LOCAL_DATA_DIR = "/mnt/data/yolo_sidewalk"

Â  Â  NUM_EPOCHS = 50

Â  Â  BATCH_SIZE = 256Â  # Total batch size across all GPUs

Â  Â  DEVICE = '0,1,2,3'Â  # Use 4 GPUs

Â  Â  SAVE_PERIOD = 1



Â  Â  # Create YOLO config directory

Â  Â  os.makedirs('/tmp/yolo_config', exist_ok=True)



Â  Â  # Azure connection string

Â  Â  connection_string = "DefaultEndpointsProtocol=https;AccountName=resnettrainingdata;AccountKey=afq0lgt0sj3lq1+b3Y6eeIg+JArkqE5UJL7tHSeM+Bxa0S3aQSK9ZRMZHozGg1PJx2rGfwBh7DySr+ASt3w6JmA==;EndpointSuffix=core.windows.net"



Â  Â  print(f"Using devices: {DEVICE}")

Â  Â  print(f"Total batch size: {BATCH_SIZE} (will be split across 4 GPUs)")



Â  Â  # Download data from Azure

Â  Â  download_from_azure(

Â  Â  Â  Â  connection_string=connection_string,

Â  Â  Â  Â  container_name=SOURCE_DATA_CONTAINER,

Â  Â  Â  Â  local_dir=LOCAL_DATA_DIR

Â  Â  )



Â  Â  # Create/update data.yaml

Â  Â  data_yaml_path = create_data_yaml(LOCAL_DATA_DIR)

Â  Â  print(f"Data configuration file: {data_yaml_path}")



Â  Â  # Initialize variables

Â  Â  start_epoch = 0

Â  Â  resume_path = None

Â  Â  training_state = None



Â  Â  # Check for existing checkpoint in Azure

Â  Â  print(f"Checking for existing checkpoints in Azure container '{CHECKPOINT_CONTAINER}'...")

Â  Â  try:

Â  Â  Â  Â  blob_service_client = BlobServiceClient.from_connection_string(connection_string)

Â  Â  Â  Â  container_client = blob_service_client.get_container_client(CHECKPOINT_CONTAINER)



Â  Â  Â  Â  # List all checkpoint blobs

Â  Â  Â  Â  checkpoints = [blob.name for blob in container_client.list_blobs() if blob.name.startswith('checkpoint_epoch_') and blob.name.endswith('.tar')]



Â  Â  Â  Â  if checkpoints:

Â  Â  Â  Â  Â  Â  # Sort to find latest

Â  Â  Â  Â  Â  Â  checkpoints.sort(key=lambda x: int(x.split('_')[2].split('.')[0]))

Â  Â  Â  Â  Â  Â  latest_checkpoint = checkpoints[-1]

Â  Â  Â  Â  Â  Â  latest_epoch = int(latest_checkpoint.split('_')[2].split('.')[0])



Â  Â  Â  Â  Â  Â  print(f"Found checkpoint: {latest_checkpoint}")



Â  Â  Â  Â  Â  Â  # Download and extract checkpoint

Â  Â  Â  Â  Â  Â  with tempfile.TemporaryDirectory() as temp_dir:

Â  Â  Â  Â  Â  Â  Â  Â  checkpoint_dir = download_and_extract_checkpoint(

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  connection_string, CHECKPOINT_CONTAINER, latest_checkpoint, temp_dir

Â  Â  Â  Â  Â  Â  Â  Â  )



Â  Â  Â  Â  Â  Â  Â  Â  if checkpoint_dir:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Load weights

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  weights_path = os.path.join(checkpoint_dir, 'weights.pt')

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if os.path.exists(weights_path):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  model = YOLO(weights_path)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"âœ… Loaded model weights from epoch {latest_epoch}")



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Load training state

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  state_path = os.path.join(checkpoint_dir, 'training_state.pt')

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if os.path.exists(state_path):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  training_state = torch.load(state_path)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  start_epoch = training_state['epoch']

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print(f"âœ… Loaded training state from epoch {start_epoch}")



Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Copy weights to a persistent location for resume

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  resume_path = '/tmp/resume_weights.pt'

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  shutil.copy(weights_path, resume_path)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print("Weights file not found in checkpoint, starting from scratch...")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  model = YOLO('yolo11n-seg.pt')

Â  Â  Â  Â  Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  print("Failed to extract checkpoint, starting from scratch...")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  model = YOLO('yolo11n-seg.pt')

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  print("No checkpoints found, starting from scratch...")

Â  Â  Â  Â  Â  Â  model = YOLO('yolo11n-seg.pt')



Â  Â  except Exception as e:

Â  Â  Â  Â  print(f"Error checking for checkpoints: {e}")

Â  Â  Â  Â  print("Starting training from scratch...")

Â  Â  Â  Â  model = YOLO('yolo11n-seg.pt')



Â  Â  # Store connection string and container name for callback

Â  Â  callback_config = {

Â  Â  Â  Â  'connection_string': connection_string,

Â  Â  Â  Â  'container_name': CHECKPOINT_CONTAINER,

Â  Â  Â  Â  'save_period': SAVE_PERIOD,

Â  Â  Â  Â  'data_yaml': data_yaml_path,

Â  Â  Â  Â  'start_epoch': start_epoch,

Â  Â  Â  Â  'epoch_counter': 0Â  # Track epochs manually

Â  Â  }



Â  Â  # Custom training callback to save complete checkpoints

Â  Â  def on_train_epoch_end(trainer):

Â  Â  Â  Â  """Callback to save complete checkpoint and all metrics."""

Â  Â  Â  Â  # Increment epoch counter

Â  Â  Â  Â  callback_config['epoch_counter'] += 1

Â  Â  Â  Â  actual_epoch = callback_config['start_epoch'] + callback_config['epoch_counter']

Â  Â Â 

Â  Â  Â  Â  print(f"\n--- Epoch {actual_epoch} Validation & Metrics ---")

Â  Â  Â  Â Â 

Â  Â  Â  Â  # Initialize a dictionary to hold all metrics for this epoch

Â  Â  Â  Â  epoch_metrics = {

Â  Â  Â  Â  Â  Â  'epoch': actual_epoch,

Â  Â  Â  Â  Â  Â  'train_loss': {},

Â  Â  Â  Â  Â  Â  'val_metrics': {}

Â  Â  Â  Â  }

Â  Â Â 

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  # 1. Get training losses from the trainer object

Â  Â  Â  Â  Â  Â  if hasattr(trainer, 'last_train_metrics'):

Â  Â  Â  Â  Â  Â  Â  Â  epoch_metrics['train_loss'] = trainer.last_train_metrics

Â  Â Â 

Â  Â  Â  Â  Â  Â  # 2. Run validation and get validation metrics

Â  Â  Â  Â  Â  Â  metrics = trainer.model.val(data=callback_config['data_yaml'], verbose=False)

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  # Store box and segmentation metrics

Â  Â  Â  Â  Â  Â  epoch_metrics['val_metrics'] = {

Â  Â  Â  Â  Â  Â  Â  Â  'box': {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'precision': metrics.box.p.mean(),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'recall': metrics.box.r.mean(),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'map50': metrics.box.map50,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'map50_95': metrics.box.map

Â  Â  Â  Â  Â  Â  Â  Â  },

Â  Â  Â  Â  Â  Â  Â  Â  'seg': {

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'precision': metrics.seg.p.mean(),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'recall': metrics.seg.r.mean(),

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'map50': metrics.seg.map50,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  'map50_95': metrics.seg.map

Â  Â  Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  }

Â  Â Â 

Â  Â  Â  Â  Â  Â  # Print metrics for real-time monitoring

Â  Â  Â  Â  Â  Â  print(f"Â  Training Box Loss: {epoch_metrics['train_loss'].get('box_loss', 'N/A'):.4f}")

Â  Â  Â  Â  Â  Â  print(f"Â  Training Seg Loss: {epoch_metrics['train_loss'].get('seg_loss', 'N/A'):.4f}")

Â  Â  Â  Â  Â  Â  print(f"Â  Validation mAP50-95 (Box): {epoch_metrics['val_metrics']['box']['map50_95']:.4f}")

Â  Â  Â  Â  Â  Â  print(f"Â  Validation mAP50-95 (Seg): {epoch_metrics['val_metrics']['seg']['map50_95']:.4f}")

Â  Â Â 

Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  print(f"Error calculating or retrieving metrics: {e}")

Â  Â  Â  Â Â 

Â  Â  Â  Â  print("---------------------------------------------")

Â  Â Â 

Â  Â  Â  Â  # 3. Save the collected metrics to a file in /mnt/data

Â  Â  Â  Â  results_path = "/mnt/data/training_metrics.jsonl"

Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  with open(results_path, 'a') as f:

Â  Â  Â  Â  Â  Â  Â  Â  # Convert dictionary to a JSON string and write it as a new line

Â  Â  Â  Â  Â  Â  Â  Â  f.write(json.dumps(epoch_metrics) + '\n')

Â  Â  Â  Â  Â  Â  print(f"âœ… Metrics for epoch {actual_epoch} saved to {results_path}")

Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  print(f"âŒ Failed to save metrics for epoch {actual_epoch}. Error: {e}")

Â  Â Â 

Â  Â  Â  Â  # --- Your existing checkpoint saving logic ---

Â  Â  Â  Â  if actual_epoch % callback_config['save_period'] == 0:

Â  Â  Â  Â  Â  Â  print(f"ğŸ“¸ Saving checkpoint at epoch {actual_epoch}...")

Â  Â  Â  Â  Â  Â  save_full_checkpoint_to_azure(

Â  Â  Â  Â  Â  Â  Â  Â  trainer,

Â  Â  Â  Â  Â  Â  Â  Â  callback_config['connection_string'],

Â  Â  Â  Â  Â  Â  Â  Â  callback_config['container_name'],

Â  Â  Â  Â  Â  Â  Â  Â  actual_epoch

Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  next_save = ((actual_epoch // callback_config['save_period']) + 1) * callback_config['save_period']

Â  Â  Â  Â  Â  Â  print(f"â„¹ï¸Â  Epoch {actual_epoch} - Not saving checkpoint (next save at epoch {next_save})")



Â  Â  # Also add a callback that runs after each epoch completes (alternative hook)

Â  Â  def on_train_epoch_end_alt(trainer):

Â  Â  Â  Â  """Alternative callback using on_epoch_end hook."""

Â  Â  Â  Â  # This might work better for checkpoint saving

Â  Â  Â  Â  callback_config['epoch_counter'] = trainer.epoch + 1

Â  Â  Â  Â  actual_epoch = callback_config['start_epoch'] + callback_config['epoch_counter']



Â  Â  Â  Â  if actual_epoch % callback_config['save_period'] == 0:

Â  Â  Â  Â  Â  Â  print(f"ğŸ“¸ [Alt] Saving checkpoint at epoch {actual_epoch}")

Â  Â  Â  Â  Â  Â  save_full_checkpoint_to_azure(

Â  Â  Â  Â  Â  Â  Â  Â  trainer,

Â  Â  Â  Â  Â  Â  Â  Â  callback_config['connection_string'],

Â  Â  Â  Â  Â  Â  Â  Â  callback_config['container_name'],

Â  Â  Â  Â  Â  Â  Â  Â  actual_epoch

Â  Â  Â  Â  Â  Â  )



Â  Â  # Add callbacks to model

Â  Â  model.add_callback("on_train_epoch_end", on_train_epoch_end)

Â  Â  # Try both hooks to ensure we catch the epoch end

Â  Â  model.add_callback("on_epoch_end", on_train_epoch_end_alt)



Â  Â  # Use temporary directory for YOLO's internal outputs

Â  Â  with tempfile.TemporaryDirectory() as temp_project_dir:

Â  Â  Â  Â  # Calculate remaining epochs

Â  Â  Â  Â  remaining_epochs = NUM_EPOCHS - start_epoch



Â  Â  Â  Â  if remaining_epochs <= 0:

Â  Â  Â  Â  Â  Â  print(f"Training already completed ({start_epoch} epochs done, target was {NUM_EPOCHS})")

Â  Â  Â  Â  Â  Â  return



Â  Â  Â  Â  # Train the model

Â  Â  Â  Â  print(f"\nStarting training from epoch {start_epoch + 1} to {NUM_EPOCHS}...")

Â  Â  Â  Â  print(f"Training for {remaining_epochs} more epochs...")



Â  Â  Â  Â  # Prepare training arguments

Â  Â  Â  Â  train_args = {

Â  Â  Â  Â  Â  Â  'data': data_yaml_path,

Â  Â  Â  Â  Â  Â  'epochs': remaining_epochs,Â  # Train only remaining epochs

Â  Â  Â  Â  Â  Â  'batch': BATCH_SIZE,

Â  Â  Â  Â  Â  Â  'imgsz': 640,

Â  Â  Â  Â  Â  Â  'device': DEVICE,

Â  Â  Â  Â  Â  Â  'workers': 8,

Â  Â  Â  Â  Â  Â  'patience': 30,Â  # Disable early stopping

Â  Â  Â  Â  Â  Â  'save': True,

Â  Â  Â  Â  Â  Â  'save_period': -1,Â  # Disable default saving

Â  Â  Â  Â  Â  Â  'project': temp_project_dir,

Â  Â  Â  Â  Â  Â  'name': 'yolov11n_seg_sidewalk',

Â  Â  Â  Â  Â  Â  'exist_ok': True,

Â  Â  Â  Â  Â  Â  'pretrained': False,Â  # Already have a model

Â  Â  Â  Â  Â  Â  'resume': resume_path if resume_path and os.path.exists(resume_path) else False,

Â  Â  Â  Â  Â  Â  'optimizer': 'auto',

Â  Â  Â  Â  Â  Â  'verbose': True,

Â  Â  Â  Â  Â  Â  'seed': 42,

Â  Â  Â  Â  Â  Â  'deterministic': True,

Â  Â  Â  Â  Â  Â  'single_cls': True,

Â  Â  Â  Â  Â  Â  'amp': True,



Â  Â  Â  Â  Â  Â  # Augmentation parameters

Â  Â  Â  Â  Â  Â  'hsv_h': 0.015,

Â  Â  Â  Â  Â  Â  'hsv_s': 0.7,

Â  Â  Â  Â  Â  Â  'hsv_v': 0.4,

Â  Â  Â  Â  Â  Â  'degrees': 0.0,

Â  Â  Â  Â  Â  Â  'translate': 0.1,

Â  Â  Â  Â  Â  Â  'scale': 0.5,

Â  Â  Â  Â  Â  Â  'shear': 0.0,

Â  Â  Â  Â  Â  Â  'perspective': 0.0,

Â  Â  Â  Â  Â  Â  'flipud': 0.0,

Â  Â  Â  Â  Â  Â  'fliplr': 0.5,

Â  Â  Â  Â  Â  Â  'mosaic': 1.0,

Â  Â  Â  Â  Â  Â  'mixup': 0.0,

Â  Â  Â  Â  Â  Â  'copy_paste': 0.0,



Â  Â  Â  Â  Â  Â  # Segmentation specific

Â  Â  Â  Â  Â  Â  'overlap_mask': True,

Â  Â  Â  Â  Â  Â  'mask_ratio': 4,

Â  Â  Â  Â  }



Â  Â  Â  Â  # If we have training state and optimizer state, we need to properly resume

Â  Â  Â  Â  if training_state and resume_path:

Â  Â  Â  Â  Â  Â  # YOLO's resume functionality should handle optimizer state loading

Â  Â  Â  Â  Â  Â  train_args['resume'] = resume_path



Â  Â  Â  Â  results = model.train(**train_args)



Â  Â  Â  Â  # Save final model and checkpoint

Â  Â  Â  Â  print("\nSaving final model to Azure...")



Â  Â  Â  Â  # Save as both final model and final checkpoint

Â  Â  Â  Â  final_blob_name = "yolov11n_seg_sidewalk_final.pt"

Â  Â  Â  Â  # Point to the model from the last epoch instead of the best one

Â  Â  Â  Â  final_model_path = os.path.join(temp_project_dir, 'yolov11n_seg_sidewalk', 'weights', 'last.pt')

Â  Â  Â  Â Â 

Â  Â  Â  Â  if os.path.exists(final_model_path):

Â  Â  Â  Â  Â  Â  try:

Â  Â  Â  Â  Â  Â  Â  Â  blob_service_client = BlobServiceClient.from_connection_string(connection_string)

Â  Â  Â  Â  Â  Â  Â  Â  blob_client = blob_service_client.get_blob_client(

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  container=CHECKPOINT_CONTAINER,Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  blob=final_blob_name

Â  Â  Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  with open(final_model_path, "rb") as data:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  blob_client.upload_blob(data, overwrite=True)

Â  Â  Â  Â  Â  Â  Â  Â  print(f"âœ… Final model from the last epoch uploaded to Azure as: {final_blob_name}")

Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  Â  Â  # Also save a complete final checkpoint

Â  Â  Â  Â  Â  Â  Â  Â  # Get trainer from the model's last training session

Â  Â  Â  Â  Â  Â  Â  Â  if hasattr(model, 'trainer'):

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  save_full_checkpoint_to_azure(

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  model.trainer,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  connection_string,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  CHECKPOINT_CONTAINER,

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  NUM_EPOCHS

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  except Exception as e:

Â  Â  Â  Â  Â  Â  Â  Â  print(f"Failed to upload final model: {e}")



Â  Â  Â  Â  # Validate the model

Â  Â  Â  Â  print("\n=== Running Final Validation ===")

Â  Â  Â  Â  metrics = model.val()

Â  Â  Â  Â  print(f"Box mAP50-95: {metrics.box.map}")

Â  Â  Â  Â  print(f"Mask mAP50-95: {metrics.seg.map}")



Â  Â  # Clean up resume weights if exists

Â  Â  if resume_path and os.path.exists(resume_path):

Â  Â  Â  Â  os.remove(resume_path)



Â  Â  print("\nâœ… Training complete!")



if __name__ == '__main__':

Â  Â  # Set multiprocessing start method

Â  Â  if multiprocessing.get_start_method(allow_none=True) != 'spawn':

Â  Â  Â  Â  multiprocessing.set_start_method('spawn', force=True)



Â  Â  main()
